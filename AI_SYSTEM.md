# ğŸ¤– Sistema Inteligente de IA - 3 Modos

## ğŸ“‹ VisÃ£o Geral

Sistema centralizado de IA com **3 modos inteligentes** que gerencia **TODOS** os recursos de inteligÃªncia artificial da plataforma.

---

## ğŸ¯ 3 MODOS DE IA

### 1ï¸âƒ£ FULL - OpenAI (Melhor Qualidade)
- **Usa:** Apenas OpenAI (GPT-4)
- **Vantagens:**
  - âœ… Melhor qualidade de respostas
  - âœ… Mais confiÃ¡vel
  - âœ… Suporta tarefas complexas
- **Desvantagens:**
  - âš ï¸ Custa dinheiro (~$0.03-$0.06/1k tokens)
  - âš ï¸ Requer conexÃ£o internet
  - âš ï¸ Depende de API key

**Quando usar:** ProduÃ§Ã£o, clientes premium, tarefas crÃ­ticas

---

### 2ï¸âƒ£ AUTO - HÃ­brido Inteligente (Recomendado) â­
- **Usa:** IA decide entre OpenAI e Ollama
- **LÃ³gica de DecisÃ£o:**
  ```
  Tarefa SIMPLES â†’ Ollama (grÃ¡tis)
  Tarefa MÃ‰DIA â†’ Ollama 70% / OpenAI 30%
  Tarefa COMPLEXA â†’ OpenAI (qualidade)
  ```
- **Vantagens:**
  - âœ… Melhor custo-benefÃ­cio
  - âœ… Balanceia qualidade e economia
  - âœ… Inteligente e adaptativo
- **AnÃ¡lise de Complexidade:**
  - Tamanho do prompt
  - Palavras-chave complexas
  - Contexto da tarefa

**Quando usar:** Desenvolvimento, uso geral, otimizaÃ§Ã£o de custos

---

### 3ï¸âƒ£ ECONOMICO - Ollama (100% GrÃ¡tis)
- **Usa:** Apenas Ollama (local)
- **Vantagens:**
  - âœ… Totalmente grÃ¡tis
  - âœ… Privado (dados nÃ£o saem do servidor)
  - âœ… Sem limites de uso
  - âœ… Funciona offline
- **Desvantagens:**
  - âš ï¸ Qualidade menor que OpenAI
  - âš ï¸ Mais lento (especialmente sem GPU)
  - âš ï¸ Requer recursos do servidor

**Quando usar:** Testes, desenvolvimento local, budget limitado

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         AIService (Core)                â”‚
â”‚  - Gerencia 3 modos                     â”‚
â”‚  - AnÃ¡lise de complexidade              â”‚
â”‚  - DecisÃ£o inteligente (AUTO mode)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚
   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”
   â”‚ OpenAI â”‚      â”‚ Ollama â”‚
   â”‚  GPT-4 â”‚      â”‚ Llama2 â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Funcionalidades Implementadas:

âœ… **Chat AI** (`/api/v1/ai/chat`)
- Conversas inteligentes com 3 modos
- Retorna: resposta, modelo usado, provider, tokens, custo

âœ… **RAG/Embeddings**
- Gera embeddings com modo inteligente
- Usa OpenAI ou Ollama baseado no modo

âœ… **Endpoints de Modo**
- `GET /api/v1/ai/mode` - Ver modo atual
- `POST /api/v1/ai/mode` - Mudar modo

---

## ğŸ”§ ConfiguraÃ§Ã£o

### Docker (Recomendado)

```bash
# Ollama jÃ¡ incluÃ­do no docker-compose.dev.yml
docker-compose -f docker-compose.dev.yml up

# Auto-download de modelos:
# - llama2 (geral)
# - mistral (mais rÃ¡pido)
```

### VariÃ¡veis de Ambiente

```.env
# Modo de IA (full | auto | economico)
AI_MODE=auto

# OpenAI (para modo FULL ou AUTO)
OPENAI_API_KEY=sk-sua-chave-aqui
OPENAI_MODEL=gpt-4

# Ollama (para modo ECONOMICO ou AUTO)
OLLAMA_URL=http://ollama:11434
OLLAMA_MODEL=llama2
```

---

## ğŸ’» Uso no CÃ³digo

### Importar AIService

```typescript
import { getAIService } from '../core/ai/ai.service';

const aiService = getAIService(prisma);
```

### Chat Simples

```typescript
const result = await aiService.complete({
  prompt: 'Explique o que Ã© TypeScript',
  systemMessage: 'VocÃª Ã© um professor de programaÃ§Ã£o.',
  temperature: 0.7,
});

console.log(result.content);   // Resposta da IA
console.log(result.provider);  // 'openai' ou 'ollama'
console.log(result.cost);      // Custo em USD (0 para Ollama)
```

### Embeddings

```typescript
const embedding = await aiService.generateEmbedding('Texto para vetorizar');
// Retorna: number[] (1536 dimensÃµes OpenAI / variÃ¡vel Ollama)
```

### AnÃ¡lise de Sentimento

```typescript
const sentiment = await aiService.analyzeSentiment('Adorei este produto!');
// Retorna: { sentiment: 'positive', score: 0.95 }
```

### SumarizaÃ§Ã£o

```typescript
const summary = await aiService.summarize(longText, 200);
// Retorna: Resumo em atÃ© 200 caracteres
```

### SugestÃµes

```typescript
const suggestions = await aiService.generateSuggestions(
  'Cliente interessado em CRM',
  'prÃ³ximos passos'
);
// Retorna: ['Agendar demo', 'Enviar proposta', ...]
```

### Mudar Modo

```typescript
import { AIMode } from '../core/ai/ai.service';

aiService.setMode(AIMode.ECONOMICO);  // Muda para Ollama
aiService.setMode(AIMode.FULL);       // Muda para OpenAI
aiService.setMode(AIMode.AUTO);       // Muda para hÃ­brido
```

---

## ğŸ¨ AplicaÃ§Ãµes

### 1. Chat AI
**Arquivo:** `AIChatPage.tsx`
```typescript
// Frontend chama:
POST /api/v1/ai/chat
{
  "message": "Como posso melhorar minhas vendas?",
  "temperature": 0.7
}

// Resposta:
{
  "message": "...",
  "provider": "ollama",  // ou "openai"
  "model": "llama2",
  "cost": 0
}
```

### 2. Zettels Inteligentes
**Recurso:** SugestÃµes automÃ¡ticas de tags e links
```typescript
// Ao criar zettel:
const suggestions = await aiService.generateSuggestions(
  zettel.content,
  'tags relacionadas'
);
```

### 3. NotificaÃ§Ãµes Inteligentes
**Recurso:** AnÃ¡lise de prioridade e sentimento
```typescript
const sentiment = await aiService.analyzeSentiment(notification.message);
if (sentiment.score < 0.3) {
  // NotificaÃ§Ã£o urgente
}
```

### 4. RAG (Busca SemÃ¢ntica)
**Recurso:** Embeddings inteligentes
```typescript
// RAGService jÃ¡ usa AIService automaticamente
const embedding = await ragService.generateEmbedding(text);
```

---

## ğŸ“Š AnÃ¡lise de Complexidade (Modo AUTO)

### Fatores Analisados:

1. **Tamanho do Prompt**
   - < 100 chars â†’ SIMPLE
   - 100-1000 chars â†’ MEDIUM
   - \> 1000 chars â†’ COMPLEX

2. **Palavras-chave**
   - **Simples:** summarize, translate, basic, quick
   - **Complexas:** analyze, technical, professional, legal, medical

3. **Contexto** (futuro)
   - HistÃ³rico do usuÃ¡rio
   - Tipo de tarefa
   - Feedback anterior

### DecisÃ£o (Modo AUTO):

```
SIMPLE â†’ 100% Ollama
MEDIUM â†’ 70% Ollama, 30% OpenAI
COMPLEX â†’ 100% OpenAI (se disponÃ­vel)
```

---

## ğŸ” Exemplos PrÃ¡ticos

### Exemplo 1: Chat Simples
```
Prompt: "OlÃ¡, como vocÃª estÃ¡?"
Complexidade: SIMPLE
Provider: Ollama
Custo: $0
```

### Exemplo 2: Tarefa MÃ©dia
```
Prompt: "Explique as melhores prÃ¡ticas de vendas B2B"
Complexidade: MEDIUM
Provider: Ollama (70% chance) ou OpenAI (30% chance)
Custo: $0 ou ~$0.03
```

### Exemplo 3: Tarefa Complexa
```
Prompt: "Analise este contrato legal de 2000 palavras e identifique riscos..."
Complexidade: COMPLEX
Provider: OpenAI (se disponÃ­vel)
Custo: ~$0.15
```

---

## ğŸ’° Economia de Custos

### CenÃ¡rio: 10.000 requests/mÃªs

| Modo | DistribuiÃ§Ã£o | Custo Mensal |
|------|--------------|--------------|
| **FULL** | 100% OpenAI | $450 |
| **AUTO** | 70% Ollama + 30% OpenAI | $135 |
| **ECONOMICO** | 100% Ollama | $0 |

**Economia com AUTO:** 70% vs FULL âœ…

---

## ğŸš€ PrÃ³ximas ImplementaÃ§Ãµes

### Planejado:
- [ ] Tracking de uso por empresa
- [ ] Dashboard de custos e mÃ©tricas
- [ ] Cache de respostas frequentes
- [ ] Fine-tuning de modelos Ollama
- [ ] Suporte a mais modelos (Claude, Gemini)
- [ ] A/B testing automÃ¡tico de modelos
- [ ] Feedback loop para melhorar decisÃµes AUTO

### Aplicar em:
- [ ] Zettels inteligentes (sugestÃµes automÃ¡ticas)
- [ ] NotificaÃ§Ãµes inteligentes (priorizaÃ§Ã£o)
- [ ] Deals (anÃ¡lise de probabilidade)
- [ ] Contacts (enriquecimento de dados)
- [ ] Workflows (automaÃ§Ã£o inteligente)

---

## ğŸ› ï¸ Troubleshooting

### âŒ "Ollama not responding"
```bash
# Verificar se Ollama estÃ¡ rodando:
docker-compose -f docker-compose.dev.yml logs ollama

# Restart Ollama:
docker-compose -f docker-compose.dev.yml restart ollama

# Baixar modelo manualmente:
docker-compose -f docker-compose.dev.yml exec ollama ollama pull llama2
```

### âŒ "OpenAI authentication failed"
```bash
# Verificar API key:
echo $OPENAI_API_KEY

# Testar manualmente:
curl https://api.openai.com/v1/chat/completions \
  -H "Authorization: Bearer $OPENAI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"model":"gpt-4","messages":[{"role":"user","content":"Hello"}]}'
```

### âŒ "Mode AUTO always using Ollama"
- Se OpenAI nÃ£o estÃ¡ configurado, AUTO = ECONOMICO
- Adicione OPENAI_API_KEY para ativar hÃ­brido real

---

## ğŸ“– API Reference

### POST /api/v1/ai/chat
**Request:**
```json
{
  "message": "Sua pergunta",
  "systemMessage": "Contexto opcional",
  "temperature": 0.7
}
```

**Response:**
```json
{
  "success": true,
  "data": {
    "message": "Resposta da IA",
    "model": "llama2",
    "provider": "ollama",
    "tokensUsed": 150,
    "cost": 0
  }
}
```

### GET /api/v1/ai/mode
**Response:**
```json
{
  "success": true,
  "data": {
    "mode": "auto"
  }
}
```

### POST /api/v1/ai/mode
**Request:**
```json
{
  "mode": "full" | "auto" | "economico"
}
```

---

## âœ… Checklist de ImplementaÃ§Ã£o

- [x] AIService centralizado criado
- [x] 3 modos implementados (FULL/AUTO/ECONOMICO)
- [x] LÃ³gica de decisÃ£o AUTO
- [x] Chat AI endpoint real
- [x] RAG/Embeddings com 3 modos
- [x] Ollama no Docker
- [x] ConfiguraÃ§Ã£o de ambiente
- [x] DocumentaÃ§Ã£o completa
- [ ] UI para seletor de modo
- [ ] Tracking de custos
- [ ] Dashboard de mÃ©tricas
- [ ] Aplicar em Zettels
- [ ] Aplicar em NotificaÃ§Ãµes

---

## ğŸŠ Status

**Implementado:** âœ… Sistema Core Completo
**Testado:** âš ï¸ Requer teste manual
**ProduÃ§Ã£o:** ğŸŸ¡ Pronto para uso (falta UI)

---

**Desenvolvido com â¤ï¸ | Completov2 AI System**
**VersÃ£o:** 1.0.0
**Data:** 31 de Dezembro de 2025
